# Bertopic Easy

### Usage example

> [!CAUTION]
> This library automatically caches embeddings on your hard drive.

````python

```shell
pip install bertopic-easy
````

```python

from bertopic_easy import pipeline
import json




```

## How this works in three steps

### Step 1 - Cluster sentences

Bertopic library clusters using embeddings from a `text-embedding-3-large` LLM model.

### Step 2 - Name clusters

Names are generated by a `o3-mini` LLM model for the resulting clusters from **Step 1**.

### Step 3 - Re-group outliers

Outlier sentences, those that did not fit into any of the Bertopic clusters
from **Step 1**, are classified by the `o3-mini` LLM using the resulting
cluster names from **Step 2**.

## Pre-requisites

-   [ ] You need to have an Azure OpenAI account with the following base LLM models deployed.

    -   `text-embedding-3-large`
    -   `o3-mini`

> [!TIP]
> Make a Github issue if you need to use more freedom on the LLM models.

## Motivation: What was my problem with Bertopic that this helper solved?

The bertopic library produced lots of outliers for my use case, and its built
in `reduce_outliers` tool gave me poor quality clusters because it hurt cluster
homogeneity. I needed a way to reduce the number of outliers without hurting
cluster homogeneity. This helper is the result of that need. I made a o3-mini
classifier to reduce the number of outliers. Also, I use the o3-mini to name
the clusters without getting near duplicate names that GPT4o produced.
